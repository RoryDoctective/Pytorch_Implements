{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-Level Rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/names/Arabic.txt', 'data/names/Chinese.txt', 'data/names/Czech.txt', 'data/names/Dutch.txt', 'data/names/English.txt', 'data/names/French.txt', 'data/names/German.txt', 'data/names/Greek.txt', 'data/names/Irish.txt', 'data/names/Italian.txt', 'data/names/Japanese.txt', 'data/names/Korean.txt', 'data/names/Polish.txt', 'data/names/Portuguese.txt', 'data/names/Russian.txt', 'data/names/Scottish.txt', 'data/names/Spanish.txt', 'data/names/Vietnamese.txt']\n",
      "Slusarski\n",
      "('Some arabic names ', [u'Khoury', u'Nahas', u'Daher', u'Gerges', u'Nazari', u'Maalouf', u'Gerges', u'Naifeh', u'Guirguis', u'Baba'])\n",
      "('str of all letters', \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'\")\n"
     ]
    }
   ],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "print(findFiles('data/names/*.txt'))\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    try:\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn'\n",
    "            and c in all_letters\n",
    "        )\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "print(unicodeToAscii(u'Ślusàrski'))\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = filename.split('/')[-1].split('.')[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print(\"Some arabic names \", category_lines[\"Arabic\"][:10])\n",
    "print(\"str of all letters\", all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 26 to 38 \n",
      "    0     0     0     0     0     0     0     0     0     1     0     0     0\n",
      "\n",
      "Columns 39 to 51 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 52 to 56 \n",
      "    0     0     0     0     0\n",
      "[torch.FloatTensor of size 1x57]\n",
      "\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "\n",
    "print(lineToTensor('Jones').size()) # 1 is the batch size, 57 is the feature size and final axis \n",
    "                                    # is for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (i2h): Linear(in_features=185, out_features=128)\n",
      "  (i2o): Linear(in_features=185, out_features=18)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      "-2.9268 -2.9361 -2.8609 -2.9766 -2.9476 -2.8867 -2.8031 -2.8718 -2.8816 -2.8843\n",
      "\n",
      "Columns 10 to 17 \n",
      "-2.8931 -2.9018 -2.8474 -2.8288 -2.9488 -2.8977 -2.8700 -2.8800\n",
      "[torch.FloatTensor of size 1x18]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(lineToTensor('Albert'))\n",
    "hidden = Variable(torch.zeros(1, n_hidden))\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('German', 6)\n"
     ]
    }
   ],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.data.topk(1) # top output and it's index\n",
    "    category_i = top_i[0][0]\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "print(categoryFromOutput(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('category =', 'Italian', '/ line =', u'Ongaro')\n",
      "('category =', 'Chinese', '/ line =', u'Gui')\n",
      "('category =', 'Chinese', '/ line =', u'Hew')\n",
      "('category =', 'Polish', '/ line =', u'Lis')\n",
      "('category =', 'French', '/ line =', u'David')\n",
      "('category =', 'Spanish', '/ line =', u'Capello')\n",
      "('category =', 'Chinese', '/ line =', u'Yep')\n",
      "('category =', 'Polish', '/ line =', u'Kozlowski')\n",
      "('category =', 'Irish', '/ line =', u\"O'Dowd\")\n",
      "('category =', 'Czech', '/ line =', u'Cermak')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = Variable(torch.LongTensor([all_categories.index(category)]))\n",
    "    line_tensor = Variable(lineToTensor(line))\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/ line =', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 % 2.8691 Boesch / Vietnamese F (German)\n",
      "5000 5 % 2.8516 Walkenhorst / Korean F (German)\n",
      "10000 10 % 2.9085 Weiss / Czech F (German)\n",
      "15000 15 % 2.8624 Sasada / Czech F (Japanese)\n",
      "20000 20 % 2.8395 Wang / Portuguese F (Korean)\n",
      "25000 25 % 2.9668 Harb / Czech F (Arabic)\n",
      "30000 30 % 2.9210 Pham / Korean F (Vietnamese)\n",
      "35000 35 % 2.9607 Kaczka / German F (Polish)\n",
      "40000 40 % 2.8153 Planick / Korean F (Czech)\n",
      "45000 45 % 2.9037 De palma / Czech F (Italian)\n",
      "50000 50 % 2.8714 O'Driscoll / Czech F (Irish)\n",
      "55000 55 % 2.8770 Matsushita / Vietnamese F (Japanese)\n",
      "60000 60 % 2.9291 Tsagunov / Czech F (Russian)\n",
      "65000 65 % 2.9661 Gifford / Czech F (English)\n",
      "70000 70 % 2.8438 Haanraats / Korean F (Dutch)\n",
      "75000 75 % 2.9290 Penner / Czech F (Dutch)\n",
      "80000 80 % 2.9257 Schoorel / Czech F (Dutch)\n",
      "85000 85 % 2.9957 Gerges / Portuguese F (Arabic)\n",
      "90000 90 % 2.9465 Montagna / German F (Italian)\n",
      "95000 95 % 2.7899 Joubert / French T\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=0.005)\n",
    "\n",
    "for epochs in range(100000):\n",
    "    hidden = rnn.initHidden()\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    \n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    if epochs % 5000 == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = 'T' if guess == category else 'F (%s)' % category\n",
    "        print('%d %d %% %.4f %s / %s %s' % (epochs, (epochs*100/ 100000), loss, line, guess, correct))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
