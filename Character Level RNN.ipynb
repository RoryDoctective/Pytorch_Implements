{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-Level Rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/names/Arabic.txt', 'data/names/Chinese.txt', 'data/names/Czech.txt', 'data/names/Dutch.txt', 'data/names/English.txt', 'data/names/French.txt', 'data/names/German.txt', 'data/names/Greek.txt', 'data/names/Irish.txt', 'data/names/Italian.txt', 'data/names/Japanese.txt', 'data/names/Korean.txt', 'data/names/Polish.txt', 'data/names/Portuguese.txt', 'data/names/Russian.txt', 'data/names/Scottish.txt', 'data/names/Spanish.txt', 'data/names/Vietnamese.txt']\n",
      "Slusarski\n",
      "('Some arabic names ', [u'Khoury', u'Nahas', u'Daher', u'Gerges', u'Nazari', u'Maalouf', u'Gerges', u'Naifeh', u'Guirguis', u'Baba'])\n",
      "('str of all letters', \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'\")\n"
     ]
    }
   ],
   "source": [
    "from io import open\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "print(findFiles('data/names/*.txt'))\n",
    "\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    try:\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn'\n",
    "            and c in all_letters\n",
    "        )\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "print(unicodeToAscii(u'Ślusàrski'))\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = filename.split('/')[-1].split('.')[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print(\"Some arabic names \", category_lines[\"Arabic\"][:10])\n",
    "print(\"str of all letters\", all_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 26 to 38 \n",
      "    0     0     0     0     0     0     0     0     0     1     0     0     0\n",
      "\n",
      "Columns 39 to 51 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 52 to 56 \n",
      "    0     0     0     0     0\n",
      "[torch.FloatTensor of size 1x57]\n",
      "\n",
      "torch.Size([5, 1, 57])\n"
     ]
    }
   ],
   "source": [
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "print(letterToTensor('J'))\n",
    "\n",
    "print(lineToTensor('Jones').size()) # 1 is the batch size, 57 is the feature size and final axis \n",
    "                                    # is for input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (i2h): Linear(in_features=185, out_features=128)\n",
      "  (i2o): Linear(in_features=185, out_features=18)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = RNN(n_letters, n_hidden, n_categories)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "\n",
      "Columns 0 to 9 \n",
      "-2.8463 -2.8522 -2.8140 -2.8626 -2.9689 -2.9459 -2.8350 -2.8607 -2.9405 -2.9855\n",
      "\n",
      "Columns 10 to 17 \n",
      "-2.7856 -2.9796 -2.9782 -2.8993 -2.9472 -2.8014 -2.8676 -2.8928\n",
      "[torch.FloatTensor of size 1x18]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = Variable(lineToTensor('Albert'))\n",
    "hidden = Variable(torch.zeros(1, n_hidden))\n",
    "\n",
    "output, next_hidden = rnn(input[0], hidden)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Japanese', 10)\n"
     ]
    }
   ],
   "source": [
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.data.topk(1) # top output and it's index\n",
    "    category_i = top_i[0][0]\n",
    "    return all_categories[category_i], category_i\n",
    "\n",
    "print(categoryFromOutput(output))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('category =', 'Korean', '/ line =', u'Li')\n",
      "('category =', 'Czech', '/ line =', u'Neisser')\n",
      "('category =', 'Greek', '/ line =', u'Close')\n",
      "('category =', 'Czech', '/ line =', u'Weichert')\n",
      "('category =', 'English', '/ line =', u'Rainey')\n",
      "('category =', 'Greek', '/ line =', u'Paloumbas')\n",
      "('category =', 'Chinese', '/ line =', u'Yim')\n",
      "('category =', 'Chinese', '/ line =', u'Shum')\n",
      "('category =', 'Japanese', '/ line =', u'Miyake')\n",
      "('category =', 'Portuguese', '/ line =', u'Mendes')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category = randomChoice(all_categories)\n",
    "    line = randomChoice(category_lines[category])\n",
    "    category_tensor = Variable(torch.LongTensor([all_categories.index(category)]))\n",
    "    line_tensor = Variable(lineToTensor(line))\n",
    "    return category, line, category_tensor, line_tensor\n",
    "\n",
    "for i in range(10):\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    print('category =', category, '/ line =', line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 % 2.8202 Antonopoulos / Polish F (Greek)\n",
      "5000 5 % 2.6244 Opova / Japanese F (Czech)\n",
      "10000 10 % 2.4098 Hutton / Scottish F (English)\n",
      "15000 15 % 3.2197 Demall / Italian F (Czech)\n",
      "20000 20 % 1.3741 Van / Chinese F (Vietnamese)\n",
      "25000 25 % 2.8789 Earl / Arabic F (English)\n",
      "30000 30 % 2.6241 Imai / Arabic F (Japanese)\n",
      "35000 35 % 1.4009 Pinho / Portuguese T\n",
      "40000 40 % 3.3792 Pellar / Scottish F (Czech)\n",
      "45000 45 % 0.6365 Vihorev / Russian T\n",
      "50000 50 % 2.6355 Santiago / Japanese F (Spanish)\n",
      "55000 55 % 0.2445 Yao / Chinese T\n",
      "60000 60 % 1.3827 Sinclair / French F (Scottish)\n",
      "65000 65 % 0.4310 Yang / Korean T\n",
      "70000 70 % 0.5866 Pelaez / Spanish T\n",
      "75000 75 % 1.7908 Sai / Chinese F (Vietnamese)\n",
      "80000 80 % 2.9340 Sorge / English F (German)\n",
      "85000 85 % 1.2986 Castro / Portuguese F (Italian)\n",
      "90000 90 % 1.8282 Daele / French F (Dutch)\n",
      "95000 95 % 1.6626 Ma / Korean F (Vietnamese)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(rnn.parameters(), lr=0.005)\n",
    "\n",
    "for epochs in range(100000):\n",
    "    hidden = rnn.initHidden()\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    category, line, category_tensor, line_tensor = randomTrainingExample()\n",
    "    \n",
    "    for i in range(line_tensor.size()[0]):\n",
    "        output, hidden = rnn(line_tensor[i], hidden)\n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epochs % 5000 == 0:\n",
    "        guess, guess_i = categoryFromOutput(output)\n",
    "        correct = 'T' if guess == category else 'F (%s)' % category\n",
    "        print('%d %d %% %.4f %s / %s %s' % (epochs, (epochs*100/ 100000), loss, line, guess, correct))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
